#!/usr/bin/env python
# -*- coding: utf-8 -*-

import os
import sys
import json
import time
import argparse
from pathlib import Path
from tqdm import tqdm
import numpy as np
from dotenv import load_dotenv
from FlagEmbedding import FlagReranker
import torch
from pdf2image import convert_from_path
from PIL import Image
import logging

# åˆ›å»ºæ—¥å¿—ç›®å½•
log_dir = Path("./log")
log_dir.mkdir(exist_ok=True)
log_file = log_dir / "multimodal_intent_test.log"

root = logging.getLogger()
for handler in root.handlers[:]:
    root.removeHandler(handler)

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler(str(log_file), mode='a', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logging.getLogger().setLevel(logging.INFO)
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

# å¼€å¤´åŠ å…¥æµ‹è¯•æ—¥å¿—
logger.info("=== å¤šæ„å›¾æ£€ç´¢æµ‹è¯•å¼€å§‹ ===")

# æ·»åŠ å¿…è¦çš„è·¯å¾„
sys.path.append("multimodal-RAG/DeepRAG_Multimodal/deep_retrieve")
# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv("D:\Desktop\multimodal-RAG\multimodal-RAG\DeepRAG_Multimodal\configs\.env")

# å¯¼å…¥å¿…è¦çš„åº“
from DeepRAG_Multimodal.deep_retrieve.ming.deepsearch_optimize_ming import DeepSearch_Beta
from DeepRAG_Multimodal.deep_retrieve.retriever_multimodal_bge import RetrieverConfig, MultimodalMatcher
from DeepRAG_Multimodal.deep_retrieve.mcts_retriever import MCTSWrapper


class MultiIntentTester:
    """å¤šæ„å›¾æ£€ç´¢æµ‹è¯•ç±»"""

    def __init__(self, strategy: str = "mcts"):
        """åˆå§‹åŒ–æµ‹è¯•å™¨"""
        self.strategy = strategy  # åœ¨setup_modelsä¹‹å‰è®¾ç½®strategy
        self.config = self.load_config()
        os.makedirs(self.config['results_dir'], exist_ok=True)
        self.setup_models()

    def load_config(self):
        """åŠ è½½é…ç½®"""
        config = {
            # è·¯å¾„é…ç½® - è¯·æ ¹æ®ä½ çš„å®é™…è·¯å¾„ä¿®æ”¹
            'test_data_path': r'D:\Desktop\colpali_longdoc\picked_LongDoc\selected_LongDocURL_public_with_subtask_category.jsonl',
            'pdf_base_dir': r'D:\Desktop\colpali_longdoc\picked_LongDoc',
            'results_dir': './test_results',

            # é‡‡æ ·é…ç½®
            'sample_size': 10,  # æµ‹è¯•10ä¸ªæ ·æœ¬
            'debug': True,  # è°ƒè¯•æ¨¡å¼ï¼šTrue=æµ‹è¯•1ä¸ªæ ·æœ¬ï¼ŒFalse=æµ‹è¯•10ä¸ªæ ·æœ¬

            # æ£€ç´¢é…ç½®
            'max_iterations': 2,
            'embedding_topk': 12,
            'rerank_topk': 4,
            'text_weight': 0.8,  # å¹³è¡¡æƒé‡
            'image_weight': 0.2,

            # æ¨¡å‹é…ç½®
            'mm_model_name': "vidore/colqwen2.5-v0.2",
            'mm_processor_name': "vidore/colqwen2.5-v0.1",
            'bge_model_name': "BAAI/bge-large-en-v1.5",
            'device': 'cuda:0',
            'batch_size': 2,
            'retrieval_mode': 'mixed',
            'ocr_method': 'pytesseract',

            # MCTSè¶…å‚ - ğŸ”¥ é™ä½å‚æ•°é¿å…å†…å­˜é—®é¢˜
            'rollout_budget': 50,  # ä»300é™ä½åˆ°50
            'k_per_intent': 3,  # ä»5é™ä½åˆ°3
            'max_depth': 5,  # ä»10é™ä½åˆ°5
            'c_puct': 1.0,  # ä»1.2é™ä½åˆ°1.0
        }

        if config['debug']:
            config['sample_size'] = 1  # è°ƒè¯•æ¨¡å¼ä¸‹åªæµ‹è¯•3ä¸ªæ ·æœ¬

        return config

    def setup_models(self):
        """åˆå§‹åŒ–æ£€ç´¢æ¨¡å‹"""
        logger.info("ğŸš€ åˆå§‹åŒ–å¤šæ„å›¾æ£€ç´¢æ¨¡å‹...")
        device = "cuda:0" if torch.cuda.is_available() else "cpu"
        logger.info(f"ğŸ® ä½¿ç”¨è®¾å¤‡: {device}")

        # ğŸ”¥ æå‰æ¸…ç†GPUå†…å­˜
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            initial_memory = torch.cuda.memory_allocated() / (1024 ** 3)
            logger.info(f"ğŸ§¹ åˆå§‹GPUå†…å­˜ä½¿ç”¨: {initial_memory:.2f}GB")

        try:
            # åˆå§‹åŒ–é‡æ’åºå™¨
            logger.info("â³ åˆå§‹åŒ–é‡æ’åºå™¨...")
            self.reranker = FlagReranker(
                model_name_or_path="BAAI/bge-reranker-large",
                use_fp16=True,
                device=device
            )

            if torch.cuda.is_available():
                after_reranker_memory = torch.cuda.memory_allocated() / (1024 ** 3)
                logger.info(f"ğŸ“Š é‡æ’åºå™¨åGPUå†…å­˜: {after_reranker_memory:.2f}GB")

            # åˆå§‹åŒ–å¤šæ¨¡æ€åŒ¹é…å™¨é…ç½®
            logger.info("â³ åˆå§‹åŒ–å¤šæ¨¡æ€åŒ¹é…å™¨...")
            retriever_config = RetrieverConfig(
                model_name=self.config['mm_model_name'],
                processor_name=self.config['mm_processor_name'],
                bge_model_name=self.config['bge_model_name'],
                device=self.config['device'],
                use_fp16=True,
                batch_size=self.config['batch_size'],
                mode=self.config['retrieval_mode'],
                ocr_method=self.config['ocr_method']
            )

            self.mm_matcher = MultimodalMatcher(
                config=retriever_config,
                embedding_weight=self.config['text_weight'],
                topk=self.config['rerank_topk']
            )
            logger.info("âœ… å·²åˆå§‹åŒ–å¤šæ¨¡æ€åŒ¹é…å™¨")

            if torch.cuda.is_available():
                after_matcher_memory = torch.cuda.memory_allocated() / (1024 ** 3)
                logger.info(f"ğŸ“Š å¤šæ¨¡æ€åŒ¹é…å™¨åGPUå†…å­˜: {after_matcher_memory:.2f}GB")

            # åˆå§‹åŒ– DeepSearch_Betaï¼ˆå¤šæ„å›¾æ‹†è§£ï¼‰æ£€ç´¢å™¨
            logger.info("â³ åˆå§‹åŒ–å¤šæ„å›¾æ£€ç´¢å™¨...")
            self.multi_intent_search = DeepSearch_Beta(
                max_iterations=self.config['max_iterations'],
                reranker=self.reranker,
                params={
                    "embedding_topk": self.config['embedding_topk'],
                    "rerank_topk": self.config['rerank_topk'],
                    "text_weight": self.config['text_weight'],
                    "image_weight": self.config['image_weight']
                }
            )

            # æ ¹æ® strategy ç»„è£…æœ€ç»ˆ"åº•å±‚æ£€ç´¢å™¨"
            if self.strategy.lower() == "mcts":
                logger.info("â™Ÿï¸  å°è¯•ä½¿ç”¨ MCTSWrapper ç»„åˆæ£€ç´¢ç»“æœ")
                try:
                    # ğŸ”¥ æ¸…ç†GPUå†…å­˜é¿å…å†²çª
                    if torch.cuda.is_available():
                        torch.cuda.empty_cache()
                        logger.info("ğŸ§¹ æ¸…ç†GPUå†…å­˜å®Œæˆ")

                    # å°è¯•å¯¼å…¥MCTSWrapper
                    from DeepRAG_Multimodal.deep_retrieve.mcts_retriever import MCTSWrapper

                    # ğŸ”¥ ä½¿ç”¨æ›´ä¿å®ˆçš„MCTSå‚æ•°é¿å…å†…å­˜é—®é¢˜
                    conservative_config = {
                        'rollout_budget': min(self.config['rollout_budget'], 30),  # è¿›ä¸€æ­¥é™ä½
                        'k_per_intent': min(self.config['k_per_intent'], 2),  # è¿›ä¸€æ­¥é™ä½
                        'max_depth': min(self.config['max_depth'], 3),  # è¿›ä¸€æ­¥é™ä½
                        'c_puct': self.config['c_puct']
                    }

                    logger.info(f"ğŸ›ï¸  ä½¿ç”¨ä¿å®ˆMCTSå‚æ•°: {conservative_config}")

                    self.retriever = MCTSWrapper(
                        base_retriever=self.mm_matcher,
                        rollout_budget=conservative_config['rollout_budget'],
                        k_per_intent=conservative_config['k_per_intent'],
                        max_depth=conservative_config['max_depth'],
                        c_puct=conservative_config['c_puct'],
                        reward_weights={"coverage": 0.8, "quality": 0.6, "diversity": 0.2},  # é™ä½æƒé‡
                    )
                    logger.info("âœ… MCTSWrapper åˆå§‹åŒ–æˆåŠŸ")

                except ImportError as e:
                    logger.warning(f"âš ï¸ æ— æ³•å¯¼å…¥MCTSWrapper: {e}")
                    logger.info("ğŸ’¡ å¦‚æœéœ€è¦ä½¿ç”¨MCTSï¼Œè¯·æ£€æŸ¥mcts_retriever.pyæ–‡ä»¶æ˜¯å¦å­˜åœ¨")
                    logger.info("ğŸ”„ å›é€€åˆ° baseline ç­–ç•¥")
                    self.retriever = self.mm_matcher
                    self.strategy = "baseline"

                except Exception as e:
                    logger.error(f"âŒ MCTSWrapper åˆå§‹åŒ–å¤±è´¥: {str(e)}")
                    logger.info("ğŸ”„ å›é€€åˆ° baseline ç­–ç•¥")
                    self.retriever = self.mm_matcher
                    self.strategy = "baseline"
            else:
                logger.info("ğŸ“„  ä½¿ç”¨ baseline å¤šæ¨¡æ€æ£€ç´¢å™¨")
                self.retriever = self.mm_matcher

            # æœ€ç»ˆå†…å­˜æ£€æŸ¥
            if torch.cuda.is_available():
                final_memory = torch.cuda.memory_allocated() / (1024 ** 3)
                logger.info(f"ğŸ“Š æœ€ç»ˆGPUå†…å­˜ä½¿ç”¨: {final_memory:.2f}GB")

            logger.info("âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆ")

        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            raise

    def load_test_data(self):
        """åŠ è½½æµ‹è¯•æ•°æ®"""
        allowed_doc_nos = [
            '4046173.pdf', '4176503.pdf', '4057524.pdf', '4064501.pdf', '4057121.pdf', '4174854.pdf',
            '4148165.pdf', '4129570.pdf', '4010333.pdf', '4147727.pdf', '4066338.pdf', '4031704.pdf',
            '4050613.pdf', '4072260.pdf', '4091919.pdf', '4094684.pdf', '4063393.pdf', '4132494.pdf',
            '4185438.pdf', '4129670.pdf', '4138347.pdf', '4190947.pdf', '4100212.pdf', '4173940.pdf',
            '4069930.pdf', '4174181.pdf', '4027862.pdf', '4012567.pdf', '4145761.pdf', '4078345.pdf',
            '4061601.pdf', '4170122.pdf', '4077673.pdf', '4107960.pdf', '4005877.pdf', '4196005.pdf',
            '4126467.pdf', '4088173.pdf', '4106951.pdf', '4086173.pdf', '4072232.pdf', '4111230.pdf',
            '4057714.pdf'
        ]

        logger.info(f"ğŸ“š åŠ è½½æµ‹è¯•æ•°æ®: {self.config['test_data_path']}")
        test_data = []

        with open(self.config['test_data_path'], 'r', encoding='utf-8') as f:
            for line in f:
                if line.strip():
                    item = json.loads(line)
                    if item.get("pdf_path") in allowed_doc_nos:
                        test_data.append(item)

        if self.config['sample_size'] > 0 and len(test_data) > self.config['sample_size']:
            np.random.seed(42)  # è®¾ç½®éšæœºç§å­ç¡®ä¿å¯é‡å¤æ€§
            test_data = np.random.choice(test_data, self.config['sample_size'], replace=False).tolist()

        logger.info(f"âœ… æˆåŠŸåŠ è½½ {len(test_data)} æ¡æµ‹è¯•æ•°æ®")
        return test_data

    def process_single_document(self, doc_data):
        """å¤„ç†å•ä¸ªæ–‡æ¡£ï¼Œä½¿ç”¨é¢„å¤„ç†æ–‡æœ¬å’ŒPDFå›¾åƒ"""
        documents = []

        # è·å–PDFæ–‡ä»¶è·¯å¾„
        pdf_path = os.path.join(self.config['pdf_base_dir'], doc_data["pdf_path"])

        try:
            pages = convert_from_path(pdf_path)
            logger.info(f"ğŸ“– æˆåŠŸè½¬æ¢PDF: {doc_data['pdf_path']}, é¡µæ•°: {len(pages)}")
        except Exception as e:
            logger.error(f"âŒ PDFè½¬æ¢å¤±è´¥: {doc_data['pdf_path']}, é”™è¯¯: {str(e)}")
            return []

        # è·å–é¢„å¤„ç†çš„OCRç»“æœ
        ocr_file = os.path.join(
            self.config['pdf_base_dir'],
            f"{self.config['ocr_method']}_save",
            f"{os.path.basename(doc_data['pdf_path']).replace('.pdf', '.json')}"
        )

        # è¯»å–é¢„å¤„ç†çš„æ–‡æœ¬æ•°æ®
        if os.path.exists(ocr_file):
            with open(ocr_file, 'r', encoding='utf-8') as f:
                loaded_data = json.load(f)
            logger.info(f"ğŸ“– æˆåŠŸè¯»å–OCRæ–‡ä»¶: {ocr_file}")
        else:
            logger.warning(f"âš ï¸ æ‰¾ä¸åˆ°OCRæ–‡ä»¶: {ocr_file}")
            # å¦‚æœæ²¡æœ‰OCRæ–‡ä»¶ï¼Œåˆ›å»ºç©ºæ–‡æœ¬
            loaded_data = {f"Page_{i + 1}": "" for i in range(len(pages))}

        # éªŒè¯é¡µé¢æ•°é‡åŒ¹é…
        if len(loaded_data) != len(pages):
            logger.warning(f"âš ï¸ OCRæ•°æ®é¡µæ•° ({len(loaded_data)}) ä¸PDFé¡µæ•° ({len(pages)}) ä¸åŒ¹é…")
            page_count = min(len(loaded_data), len(pages))
        else:
            page_count = len(pages)

        # ä¸ºæ¯ä¸€é¡µåˆ›å»ºæ–‡æ¡£å¯¹è±¡
        page_keys = list(loaded_data.keys())
        for idx in range(page_count):
            if idx >= len(pages):
                break

            # æ£€æŸ¥é¡µé¢å°ºå¯¸æ˜¯å¦æœ‰æ•ˆ
            page = pages[idx]
            width, height = page.size
            if width <= 0 or height <= 0:
                logger.warning(f"âš ï¸ è·³è¿‡æ— æ•ˆé¡µé¢ {idx + 1}ï¼šå°ºå¯¸ {width}x{height}")
                continue

            # è·å–OCRæ–‡æœ¬
            page_text = loaded_data[page_keys[idx]] if idx < len(page_keys) else ""
            if not page_text.strip():
                page_text = f"ç¬¬{idx + 1}é¡µå†…å®¹"  # å¤‡ç”¨æ–‡æœ¬

            # åˆ›å»ºæ–‡æ¡£ç»“æ„
            documents.append({
                "text": page_text,
                "image": page,
                "metadata": {
                    "page_index": idx + 1,
                    "pdf_path": doc_data.get("pdf_path", "")
                }
            })

        logger.info(f"ğŸ“‘ æˆåŠŸåˆ›å»º {len(documents)} ä¸ªæ–‡æ¡£å¯¹è±¡")

        # æ·»åŠ æ–‡æœ¬è´¨é‡æ£€æŸ¥
        total_text_length = sum(len(doc['text']) for doc in documents)
        logger.info(f"ğŸ“ æ€»æ–‡æœ¬é•¿åº¦: {total_text_length} å­—ç¬¦")

        return documents

    def test_multi_intent_retrieval(self):
        """æµ‹è¯•å¤šæ„å›¾æ£€ç´¢"""
        logger.info("ğŸ¯ å¼€å§‹å¤šæ„å›¾æ£€ç´¢æµ‹è¯•...")
        test_data = self.load_test_data()
        results = []

        for idx, doc_data in enumerate(tqdm(test_data, desc="å¤šæ„å›¾æ£€ç´¢æµ‹è¯•")):
            try:
                query = doc_data.get("question", "")
                evidence_pages = doc_data.get("evidence_pages", [])

                logger.info(f"\n{'=' * 60}")
                logger.info(f"ğŸ” å¤„ç†æ–‡æ¡£ {idx + 1}/{len(test_data)}: {doc_data.get('pdf_path', 'Unknown')}")
                logger.info(f"â“ æŸ¥è¯¢: {query}")
                logger.info(f"ğŸ“‹ è¯æ®é¡µé¢: {evidence_pages}")

                # å¤„ç†æ–‡æ¡£
                document_pages = self.process_single_document(doc_data)
                if not document_pages:
                    logger.warning(f"âš ï¸ è·³è¿‡æ–‡æ¡£ {doc_data.get('pdf_path', '')}: æ— æœ‰æ•ˆå†…å®¹")
                    continue

                # æ‰§è¡Œå¤šæ„å›¾æ£€ç´¢
                data = {
                    "query": query,
                    "documents": document_pages
                }

                start_time = time.time()
                # ğŸ”¥ ä¿®å¤ï¼šæ ¹æ®ç­–ç•¥ä½¿ç”¨ä¸åŒçš„æ£€ç´¢æ–¹æ³•
                if self.strategy.lower() == "mcts":
                    # MCTSç­–ç•¥ï¼šç›´æ¥ä½¿ç”¨retriever.retrieveæ–¹æ³•
                    retrieval_results = self.retriever.retrieve(query, document_pages)
                    # è½¬æ¢ç»“æœæ ¼å¼ä»¥åŒ¹é…é¢„æœŸ
                    retrieval_results = [
                        {
                            "text": r.get("text", ""),
                            "score": r.get("score", 0),
                            "page": r.get("metadata", {}).get("page_index", 0),
                            "metadata": r.get("metadata", {})
                        }
                        for r in retrieval_results
                    ]
                else:
                    # åŸºç¡€ç­–ç•¥ï¼šä½¿ç”¨å¤šæ„å›¾æ£€ç´¢
                    retrieval_results = self.multi_intent_search.search_retrieval(data, retriever=self.mm_matcher)

                elapsed_time = time.time() - start_time

                # æå–æ£€ç´¢ç»“æœä¸­çš„é¡µç 
                retrieved_pages = set()
                for result in retrieval_results:
                    if 'metadata' in result and 'page_index' in result['metadata']:
                        retrieved_pages.add(result['metadata']['page_index'])
                    elif 'page' in result and result['page'] is not None:
                        retrieved_pages.add(result['page'])

                # è¯„ä¼°ç»“æœ
                evidence_set = set(evidence_pages)
                correct_pages = evidence_set.intersection(retrieved_pages)

                recall = len(correct_pages) / len(evidence_set) if evidence_set else 0
                precision = len(correct_pages) / len(retrieved_pages) if retrieved_pages else 0
                f1 = 2 * recall * precision / (recall + precision) if (recall + precision) > 0 else 0

                # è·å–æ£€ç´¢åˆ†æ•°
                retrieval_scores = [r.get('score', 0) for r in retrieval_results]

                logger.info(f"â±ï¸ æ£€ç´¢è€—æ—¶: {elapsed_time:.2f}ç§’")
                logger.info(f"ğŸ¯ æ£€ç´¢åˆ°é¡µé¢: {sorted(list(retrieved_pages))}")
                logger.info(f"âœ… æ­£ç¡®é¡µé¢: {sorted(list(correct_pages))}")
                logger.info(f"ğŸ“Š æ£€ç´¢åˆ†æ•°: {retrieval_scores[:5]}")
                logger.info(f"ğŸ“ˆ å¬å›ç‡: {recall:.4f}")
                logger.info(f"ğŸ“ˆ ç²¾ç¡®ç‡: {precision:.4f}")
                logger.info(f"ğŸ“ˆ F1å€¼: {f1:.4f}")

                # è®°å½•ç»“æœ
                result = {
                    "doc_id": doc_data.get("doc_no", ""),
                    "pdf_path": doc_data.get("pdf_path", ""),
                    "query": query,
                    "evidence_pages": evidence_pages,
                    "task_tag": doc_data.get("task_tag", ""),
                    "subTask": doc_data.get("subTask", []),
                    "retrieved_pages": list(retrieved_pages),
                    "correct_pages": list(correct_pages),
                    "recall": recall,
                    "precision": precision,
                    "f1": f1,
                    "retrieval_time": elapsed_time,
                    "retrieval_scores": retrieval_scores[:10],  # ä¿å­˜å‰10ä¸ªåˆ†æ•°
                    "success": len(correct_pages) == len(evidence_set)
                }

                results.append(result)

            except Exception as e:
                logger.error(f"âŒ å¤„ç†æ–‡æ¡£ {doc_data.get('pdf_path', '')} æ—¶å‡ºé”™: {str(e)}")

        # ä¿å­˜ç»“æœ
        result_file = os.path.join(self.config['results_dir'], 'multi_intent_results.json')
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)

        # åˆ†æç»“æœ
        self.analyze_results(results)

        logger.info(f"ğŸ‰ å¤šæ„å›¾æ£€ç´¢æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {result_file}")
        return results

    def analyze_results(self, results):
        """åˆ†æå¹¶æ‰“å°æµ‹è¯•ç»“æœ"""
        if not results:
            logger.warning("âš ï¸ æ²¡æœ‰å¯ç”¨çš„ç»“æœè¿›è¡Œåˆ†æ")
            return

        # è®¡ç®—å¹³å‡æŒ‡æ ‡
        recalls = [r["recall"] for r in results]
        precisions = [r["precision"] for r in results]
        f1s = [r["f1"] for r in results]
        times = [r["retrieval_time"] for r in results]
        success_count = sum(1 for r in results if r["success"])

        # åˆ†æ•°è´¨é‡æ£€æŸ¥
        all_scores = []
        for r in results:
            all_scores.extend(r["retrieval_scores"])

        non_zero_scores = [s for s in all_scores if s > 0]

        # è®¡ç®—å¹³å‡å€¼
        avg_recall = np.mean(recalls)
        avg_precision = np.mean(precisions)
        avg_f1 = np.mean(f1s)
        avg_time = np.mean(times)
        success_rate = success_count / len(results) * 100

        # æ‰“å°ç»“æœ
        logger.info(f"\n{'=' * 60}")
        logger.info(f"ğŸ“Š å¤šæ„å›¾æ£€ç´¢æ€§èƒ½åˆ†æ")
        logger.info(f"{'=' * 60}")
        logger.info(f"ğŸ“‹ æµ‹è¯•æ–‡æ¡£æ•°: {len(results)}")
        logger.info(f"ğŸ“ˆ å¹³å‡å¬å›ç‡: {avg_recall:.4f}")
        logger.info(f"ğŸ“ˆ å¹³å‡ç²¾ç¡®ç‡: {avg_precision:.4f}")
        logger.info(f"ğŸ“ˆ å¹³å‡F1å€¼: {avg_f1:.4f}")
        logger.info(f"â±ï¸ å¹³å‡æ£€ç´¢æ—¶é—´: {avg_time:.2f}ç§’")
        logger.info(f"ğŸ¯ æˆåŠŸç‡: {success_rate:.2f}% ({success_count}/{len(results)})")

        # åˆ†æ•°è´¨é‡åˆ†æ
        logger.info(f"\nğŸ“Š åˆ†æ•°è´¨é‡åˆ†æ:")
        logger.info(f"   æ€»åˆ†æ•°æ•°é‡: {len(all_scores)}")
        logger.info(f"   éé›¶åˆ†æ•°æ•°é‡: {len(non_zero_scores)}")
        if non_zero_scores:
            logger.info(f"   éé›¶åˆ†æ•°æ¯”ä¾‹: {len(non_zero_scores) / len(all_scores) * 100:.1f}%")
            logger.info(f"   æœ€é«˜åˆ†æ•°: {max(non_zero_scores):.4f}")
            logger.info(f"   å¹³å‡éé›¶åˆ†æ•°: {np.mean(non_zero_scores):.4f}")

        if len(non_zero_scores) == 0:
            logger.warning(f"âš ï¸ æ‰€æœ‰æ£€ç´¢åˆ†æ•°éƒ½ä¸º0ï¼Œè¯·æ£€æŸ¥é…ç½®ï¼")
        elif len(non_zero_scores) / len(all_scores) < 0.1:
            logger.warning(f"âš ï¸ å¤§éƒ¨åˆ†æ£€ç´¢åˆ†æ•°ä¸º0ï¼Œæ£€ç´¢æ•ˆæœå¯èƒ½æœ‰é—®é¢˜")
        else:
            logger.info(f"âœ… æ£€ç´¢åˆ†æ•°æ­£å¸¸")

        # æŒ‰ä»»åŠ¡ç±»å‹åˆ†æï¼ˆå¦‚æœæœ‰ï¼‰
        task_types = {}
        for r in results:
            task_tag = r.get("task_tag", "Unknown")
            if task_tag not in task_types:
                task_types[task_tag] = {"count": 0, "f1_sum": 0, "success": 0}

            task_types[task_tag]["count"] += 1
            task_types[task_tag]["f1_sum"] += r["f1"]
            task_types[task_tag]["success"] += 1 if r["success"] else 0

        if len(task_types) > 1:
            logger.info(f"\nğŸ“‹ æŒ‰ä»»åŠ¡ç±»å‹åˆ†æ:")
            for task_tag, stats in task_types.items():
                count = stats["count"]
                avg_f1 = stats["f1_sum"] / count
                success_rate = stats["success"] / count * 100
                logger.info(f"   {task_tag}: F1={avg_f1:.4f}, æˆåŠŸç‡={success_rate:.1f}% ({count}æ ·æœ¬)")

        logger.info(f"{'=' * 60}")

    def run(self):
        """è¿è¡Œæµ‹è¯•"""
        logger.info("ğŸš€ å¼€å§‹å¤šæ„å›¾æ£€ç´¢æµ‹è¯•...")
        start_time = time.time()

        try:
            results = self.test_multi_intent_retrieval()

            total_time = time.time() - start_time
            logger.info(f"\nğŸ‰ æµ‹è¯•å®Œæˆï¼")
            logger.info(f"â±ï¸ æ€»è€—æ—¶: {total_time:.2f}ç§’")
            logger.info(f"ğŸ“ ç»“æœå·²ä¿å­˜åˆ°: {self.config['results_dir']}")

        except Exception as e:
            logger.error(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}", exc_info=True)


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ å¤šæ„å›¾æ£€ç´¢æµ‹è¯• (é»˜è®¤MCTSç­–ç•¥)")
    print("=" * 50)
    print("ğŸ’¡ å¦‚éœ€åˆ‡æ¢ç­–ç•¥:")
    print("   - MCTSç­–ç•¥ (æ™ºèƒ½å¢å¼º): ç›´æ¥è¿è¡Œå³å¯")
    print("   - Baselineç­–ç•¥ (æ ‡å‡†): ä¿®æ”¹ä»£ç ä¸­ strategy='baseline'")
    print("=" * 50)

    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description="å¤šæ„å›¾æ£€ç´¢æµ‹è¯•å·¥å…·")
    parser.add_argument(
        "--strategy",
        default="mcts",  # ğŸ”¥ æ”¹ä¸ºé»˜è®¤MCTS
        choices=["baseline", "mcts"],
        help="é€‰æ‹©æ£€ç´¢ç­–ç•¥ï¼šbaseline=æ ‡å‡†å¤šæ¨¡æ€æ£€ç´¢ï¼›mcts=Monte-Carlo Tree Searchå¢å¼ºæ£€ç´¢"
    )
    parser.add_argument(
        "--debug",
        action="store_true",
        help="å¯ç”¨è°ƒè¯•æ¨¡å¼ï¼ˆæµ‹è¯•æ›´å°‘çš„æ ·æœ¬ï¼‰"
    )

    try:
        args = parser.parse_args()
    except SystemExit:
        # å¦‚æœæ²¡æœ‰ä¼ é€’å‚æ•°æˆ–å‚æ•°é”™è¯¯ï¼Œä½¿ç”¨é»˜è®¤å€¼
        logger.info("ğŸ“ ä½¿ç”¨é»˜è®¤å‚æ•°è¿è¡Œ (MCTSç­–ç•¥)")
        args = argparse.Namespace(strategy="mcts", debug=False)  # ğŸ”¥ æ”¹ä¸ºé»˜è®¤ä½¿ç”¨MCTS

    logger.info(f"ğŸ›ï¸  æ£€ç´¢ç­–ç•¥: {args.strategy.upper()}")
    if args.strategy == "mcts":
        logger.info("ğŸ’¡ ä½¿ç”¨Monte-Carlo Tree Searchå¢å¼ºæ£€ç´¢")
    logger.info(f"ğŸ› è°ƒè¯•æ¨¡å¼: {args.debug}")

    # åˆ›å»ºæµ‹è¯•å™¨å¹¶è¿è¡Œ
    tester = MultiIntentTester(strategy=args.strategy)

    # ğŸ”¥ å¦‚æœç­–ç•¥è¢«è‡ªåŠ¨åˆ‡æ¢ï¼Œé€šçŸ¥ç”¨æˆ·
    if args.strategy == "mcts" and tester.strategy == "baseline":
        logger.info("ğŸ’¡ å·²è‡ªåŠ¨åˆ‡æ¢åˆ°baselineç­–ç•¥ï¼Œå¦‚éœ€ä½¿ç”¨MCTSè¯·æ£€æŸ¥ç›¸å…³ä¾èµ–")

    elif args.strategy == "mcts" and tester.strategy == "mcts":
        logger.info("ğŸ‰ MCTSç­–ç•¥åˆå§‹åŒ–æˆåŠŸï¼Œå¼€å§‹å¢å¼ºæ£€ç´¢ï¼")

    tester.run()


if __name__ == "__main__":
    main()