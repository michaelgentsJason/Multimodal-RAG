import json
from copy import deepcopy
from typing import List, Dict, Annotated, Optional, Any
from DeepRAG_Multimodal.deep_retrieve.ming.agent_gpt4 import AzureGPT4Chat, create_response_format
from datetime import datetime
import sys
from DeepRAG_Multimodal.deep_retrieve.retriever_multimodal_bge import DocumentRetriever, RetrieverConfig, MultimodalMatcher
import asyncio
import concurrent.futures
from textwrap import dedent
from langchain_core.documents import Document
from FlagEmbedding import FlagReranker, FlagModel
from DeepRAG_Multimodal.deep_retrieve.deepsearch import DeepSearch_Alpha
import numpy as np
import pytesseract
from pdf2image import convert_from_path
import os
import logging

sys.path.append(os.path.join(os.path.dirname(__file__), ".."))

# # Ensure the directory for the log file exists
# log_file_path = "/Users/chloe/Documents/Academic/AI/Project/åŸºäºColpaliçš„å¤šæ¨¡æ€æ£€ç´¢æ ‡å‡†æ¡†æ¶/multimodal-RAG/DeepRAG_Multimodal/deep_retrieve/ming/deepsearch.log"
# os.makedirs(os.path.dirname(log_file_path), exist_ok=True)
#
# # Configure logger
# logger.basicConfig(
#     filename=log_file_path,
#     level=logger.INFO,
#     format="%(asctime)s - %(levelname)s - %(message)s"
# )
#
# logger.info("logger setup complete. This is a test log message.")
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)
logger.info("DeepSearch_Betaæ¨¡å—åˆå§‹åŒ–")
print(f"å½“å‰æ¨¡å—çš„æ—¥å¿—å™¨åç§°: {logger.name}")

class DeepSearch_Beta(DeepSearch_Alpha):
    def __init__(self, max_iterations: int = 2, reranker: FlagReranker = None, params: dict = None):
        super().__init__(max_iterations, reranker, params)

    def result_processor(self, results):
        matched_docs = []
        for doc, score in results:
            matched_docs.append({
                'text': doc.page_content,
                'score': 1 - score,
                'image_score': doc.metadata.get('image_score', 0),
                'text_score': doc.metadata.get('text_score', 0)
            })
        return matched_docs

    def llm_rerank(self, query, retrieval_list, reranker, topk=None):
        pairs = [[query, doc['text']] for doc in retrieval_list]
        rerank_scores = reranker.compute_score(pairs, normalize=True)
        output_list = []
        for score, doc in sorted(zip(rerank_scores, retrieval_list), key=lambda x: x[0], reverse=True):
            output_list.append({
                'text': doc['text'],
                'page': doc['metadata']['page_index'],
                'score': score,
                # 'image_score': doc['image_score'],
                # 'text_score': doc['text_score']
            })
        if topk is not None:
            output_list = output_list[:topk]
        return output_list

    def rerank_index_processor(self, results):
        """é»˜è®¤çš„ç›¸ä¼¼æ€§æœç´¢ç»“æœå¤„ç†å™¨"""
        matched_docs = []
        for doc, score in results:
            # åˆ›å»ºæ–°å­—å…¸è€Œä¸æ˜¯ä¿®æ”¹Documentå¯¹è±¡
            matched_doc = {
                'text': doc.page_content,
                'score': 1 - score,
                # å¤åˆ¶å…ƒæ•°æ®ï¼ˆå¦‚æœæœ‰éœ€è¦ï¼‰
                **doc.metadata
            }
            matched_docs.append(matched_doc)
        return matched_docs

    def search_retrieval(self, data: dict, retriever: MultimodalMatcher):
        original_query = deepcopy(data['query'])
        data_ori = deepcopy(data)
        embedding_topk = self.params['embedding_topk']
        rerank_topk = self.params['rerank_topk']

        # ç¬¬ä¸€æ­¥ï¼šä½¿ç”¨LLMæ‹†åˆ†æŸ¥è¯¢æ„å›¾
        intent_queries = self._split_query_intent(original_query)
        # intent_queries = self._split_query_intent_exist(original_query)
        logger.info(f"ğŸ” æ„å›¾æ‹†åˆ†ç»“æœ: {intent_queries}")

        all_search_results = {}
        final_search_results = []
        seen_texts = set()

        # ç¬¬äºŒæ­¥ï¼šå¯¹æ¯ä¸ªæ„å›¾è¿›è¡Œç¬¬ä¸€è½®æ£€ç´¢
        for intent_idx, intent_query in enumerate(intent_queries):
            logger.info(f"ğŸ” æ£€ç´¢æ„å›¾ {intent_idx + 1}/{len(intent_queries)}: {intent_query}")

            retrieval_list = retriever.retrieve(intent_query, data['documents'])
            retrieval_list = retrieval_list[:embedding_topk // len(intent_queries)]
            for r in retrieval_list:
                if r['text'] not in seen_texts:
                    seen_texts.add(r['text'])
                    all_search_results[intent_query] = [r['text']]
                    final_search_results.append(r)

        # ç¬¬ä¸‰æ­¥ï¼šåŸºäºç¬¬ä¸€è½®æ£€ç´¢ç»“æœè¿›è¡Œæ„å›¾ç»†åŒ–
        refined_intent_queries = self._refine_query_intent(original_query, intent_queries,
                                                          json.dumps(all_search_results, ensure_ascii=False, indent=2))
        logger.info(f"ğŸ” æ„å›¾ç»†åŒ–ç»“æœ: {refined_intent_queries}")

        # ç¬¬å››æ­¥ï¼šå¯¹ç»†åŒ–åçš„æ„å›¾è¿›è¡Œç¬¬äºŒè½®æ£€ç´¢
        if set(refined_intent_queries) != set(intent_queries):
            for intent_idx, intent_query in enumerate(refined_intent_queries):
                logger.info(f"ğŸ” æ£€ç´¢ç»†åŒ–æ„å›¾ {intent_idx + 1}/{len(refined_intent_queries)}: {intent_query}")
    
                retrieval_list = retriever.retrieve(intent_query, data_ori['documents'])
    
                # åˆå¹¶ç»“æœå¹¶å»é‡
                for result in retrieval_list:
                    if result['text'] not in seen_texts:
                        seen_texts.add(result['text'])
                        final_search_results.append(result)

        # ç¬¬äº”æ­¥ï¼šå¯¹æ‰€æœ‰ç»“æœè¿›è¡Œæœ€ç»ˆæ’åº
        final_search_results = self.llm_rerank(original_query, final_search_results, self.reranker, rerank_topk)
        print("final_search_results: ", final_search_results)

        logger.info(f"ğŸ“Š æœ€ç»ˆç»“æœ: {len(final_search_results)} æ¡")

        # æå–æœ€ç»ˆç»“æœçš„é¡µç 
        final_results_with_pages = [
            {
                "text": doc['text'],
                "score": doc['score'],
                "page": doc['page']  # è·å–é¡µç 
            }
            for doc in final_search_results
        ]
        logger.info([doc['score'] for doc in final_results_with_pages])

        return sorted(final_results_with_pages, key=lambda x: x['score'], reverse=True)[:rerank_topk]

    def _split_query_intent(self, query: str) -> List[str]:
        """å°†æŸ¥è¯¢æ‹†åˆ†ä¸ºå¤šä¸ªä¸åŒç»´åº¦çš„æ„å›¾æŸ¥è¯¢"""
        SYSTEM_MESSAGE = dedent("""
        ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŸ¥è¯¢æ„å›¾åˆ†æä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†æç”¨æˆ·çš„æŸ¥è¯¢ï¼Œå¹¶å°†å…¶æ‹†åˆ†ä¸ºå¤šä¸ªä¸åŒç»´åº¦çš„å­æŸ¥è¯¢ã€‚

        è¯·éµå¾ªä»¥ä¸‹è§„åˆ™ï¼š
        1. å¦‚æœæŸ¥è¯¢åŒ…å«å¤šä¸ªä¸åŒçš„ä¿¡æ¯éœ€æ±‚æˆ–å…³æ³¨ç‚¹ï¼Œè¯·å°†å…¶æ‹†åˆ†ä¸ºå¤šä¸ªå­æŸ¥è¯¢
        2. ç¡®ä¿æ¯ä¸ªå­æŸ¥è¯¢å…³æ³¨ä¸åŒçš„ç»´åº¦æˆ–æ–¹é¢ï¼Œä¿è¯å¤šæ ·æ€§
        3. ä¸è¦ä»…ä»…æ”¹å˜é—®é¢˜çš„è¡¨è¿°å½¢å¼ï¼Œè€Œåº”è¯¥å…³æ³¨ä¸åŒçš„ä¿¡æ¯ç»´åº¦
        4. å¦‚æœåŸå§‹æŸ¥è¯¢å·²ç»éå¸¸æ˜ç¡®ä¸”åªå…³æ³¨å•ä¸€ç»´åº¦ï¼Œåˆ™ä¸éœ€è¦æ‹†åˆ†
        5. å­æŸ¥è¯¢åº”è¯¥æ›´åŠ å…·ä½“å’Œæ˜ç¡®ï¼Œæœ‰åŠ©äºæ£€ç´¢åˆ°æ›´ç²¾å‡†çš„ä¿¡æ¯

        è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
        {
            "intent_queries": ["å­æŸ¥è¯¢1", "å­æŸ¥è¯¢2", ...]
        }
        """)

        messages = [
            {"role": "system", "content": SYSTEM_MESSAGE},
            {"role": "user", "content": f"è¯·åˆ†æä»¥ä¸‹æŸ¥è¯¢å¹¶æ‹†åˆ†ä¸ºå¤šä¸ªä¸åŒç»´åº¦çš„å­æŸ¥è¯¢ï¼š\n\n{query}"}
        ]

        response_format = create_response_format({
            "intent_queries": {
                "type": "array",
                "description": "æ‹†åˆ†åçš„å­æŸ¥è¯¢åˆ—è¡¨",
                "items": {"type": "string"}
            }
        })

        response = AzureGPT4Chat().chat_with_message_format(
            message_list=messages,
            # response_format=response_format
        )

        try:
            result = parse_llm_response(response)
            intent_queries = result.get("intent_queries", [query])
            print("intent_queries:", intent_queries)
            return intent_queries if intent_queries else [query]
        except Exception as e:
            logger.error(f"æ„å›¾æ‹†åˆ†å‡ºé”™: {e}")
            return [query]

    def _split_query_intent_exist(self, query: str) -> List[str]:
        """Directly fetch expanded queries from the JSONL file if the question matches the query."""
        jsonl_path = "/Users/chloe/Documents/Academic/AI/Project/åŸºäºColpaliçš„å¤šæ¨¡æ€æ£€ç´¢æ ‡å‡†æ¡†æ¶/multimodal-RAG/DeepRAG_Multimodal/deep_retrieve/query_expansion_task.jsonl"
        try:
            with open(jsonl_path, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()  # Remove leading/trailing whitespace
                    if not line:  # Skip empty lines
                        continue
                    try:
                        # Ensure the line is a valid JSON object
                        if line.startswith("[") or line.startswith("]") or line.startswith("}"):
                            continue  # Skip invalid lines like stray brackets
                        task = json.loads(line)  # Parse JSON line
                        if task.get("question") == query:
                            return [
                                task["Understanding"]["expanded_query"],
                                task["Reasoning"]["expanded_query"],
                                task["Locating"]["expanded_query"]
                            ]
                    except json.JSONDecodeError as e:
                        logger.error(f"Skipping invalid JSON line: {line[:50]}... Error: {e}")
        except Exception as e:
            logger.error(f"Error reading expanded queries from {jsonl_path}: {e}")
        return [query]  # Fallback to the original query if no match is found

    def _refine_query_intent(self, original_query: str, intent_queries: List[str], context: str) -> List[str]:
        """åŸºäºæ£€ç´¢ç»“æœç»†åŒ–æŸ¥è¯¢æ„å›¾"""
        # SYSTEM_MESSAGE = dedent("""
        # ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŸ¥è¯¢æ„å›¾ä¼˜åŒ–ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯åŸºäºå·²æœ‰çš„æ£€ç´¢ç»“æœï¼Œè¿›ä¸€æ­¥ç»†åŒ–å’Œä¼˜åŒ–æŸ¥è¯¢æ„å›¾ã€‚

        # è¯·éµå¾ªä»¥ä¸‹è§„åˆ™ï¼š
        # 1. åˆ†æå·²æœ‰æ£€ç´¢ç»“æœï¼Œè¯†åˆ«ä¿¡æ¯ç¼ºå£å’Œéœ€è¦è¿›ä¸€æ­¥æ¢ç´¢çš„æ–¹å‘
        # 2. åŸºäºåŸå§‹æŸ¥è¯¢å’Œå·²æ‹†åˆ†çš„æ„å›¾ï¼Œç”Ÿæˆæ›´åŠ ç²¾ç¡®çš„å­æŸ¥è¯¢
        # 3. ç¡®ä¿æ–°çš„å­æŸ¥è¯¢èƒ½å¤Ÿè¦†ç›–åŸå§‹æŸ¥è¯¢æœªè¢«æ»¡è¶³çš„ä¿¡æ¯éœ€æ±‚
        # 4. å­æŸ¥è¯¢åº”è¯¥æ›´åŠ å…·ä½“ï¼ŒåŒ…å«ä¸“ä¸šæœ¯è¯­å’Œæ˜ç¡®çš„ä¿¡æ¯éœ€æ±‚
        # 5. é¿å…ç”Ÿæˆè¿‡äºç›¸ä¼¼çš„å­æŸ¥è¯¢ï¼Œä¿è¯å¤šæ ·æ€§

        # è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
        # {
        #     "refined_intent_queries": ["ç»†åŒ–å­æŸ¥è¯¢1", "ç»†åŒ–å­æŸ¥è¯¢2", ...]
        # }
        # """)

        SYSTEM_MESSAGE = dedent("""
        You are a professional query intent optimization expert. Your task is to refine and enhance the user's search intent based on the retrieved content.

        Please follow these guidelines:
        1. Analyze the retrieved content to identify information gaps and areas that require further exploration.
        2. Based on the original query and the decomposed intent queries, generate more precise and targeted sub-queries.
        3. Ensure that the new sub-queries address the information needs that were not fully satisfied by the original query.
        4. Sub-queries should be more specific, incorporating domain-specific terminology and clearly defined information requirements.
        5. Avoid generating overly similar sub-queries; ensure diversity and coverage of different aspects.
        6. Limit the number of refined sub-queries to a maximum of **three**.

        Return your output in JSON format with the following structure:
        {
            "refined_intent_queries": ["Refined sub-query 1", "Refined sub-query 2", ...]
        }
        """)

        # messages = [
        #     {"role": "system", "content": SYSTEM_MESSAGE},
        #     {"role": "user", "content": f"""
        #     åŸå§‹æŸ¥è¯¢ï¼š
        #     {original_query}

        #     å·²æ‹†åˆ†çš„æ„å›¾æŸ¥è¯¢ï¼š
        #     {json.dumps(intent_queries, ensure_ascii=False)}

        #     å·²æ£€ç´¢åˆ°çš„å†…å®¹ï¼š
        #     {context}

        #     è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼Œç»†åŒ–å’Œä¼˜åŒ–æŸ¥è¯¢æ„å›¾ï¼š
        #     """}
        # ]

        messages = [
            {"role": "system", "content": SYSTEM_MESSAGE},
            {"role": "user", "content": f"""
            Original query:
            {original_query}

            Decomposed intent queries:
            {json.dumps(intent_queries, ensure_ascii=False)}

            Retrieved context:
            {context}

            Based on the information above, please refine and optimize the search intent:
            """}
        ]

        response_format = create_response_format({
            "refined_intent_queries": {
                "type": "array",
                "description": "ç»†åŒ–åçš„å­æŸ¥è¯¢åˆ—è¡¨",
                "items": {"type": "string"}
            }
        })

        response = AzureGPT4Chat().chat_with_message_format(
            message_list=messages,
            # response_format=response_format
        )

        try:
            result = parse_llm_response(response)
            refined_queries = result.get("refined_intent_queries", intent_queries)
            print("Refined intent queries:", refined_queries)
            return refined_queries if refined_queries else intent_queries
        except Exception as e:
            logger.error(f"æ„å›¾ç»†åŒ–å‡ºé”™: {e}")
            return intent_queries

    def _prepare_context(self, search_results: List[Dict[str, str]]) -> str:
        """Prepare context from search results."""
        return '\n'.join([f"{index + 1}. {result['text']}" for index, result in enumerate(search_results)])


def calculate_accuracy(json_file_path, retrieved_pages):
    with open(json_file_path, 'r') as f:
        logs = [json.loads(line.strip()) for line in f]

    total = 0
    correct = 0

    for log in logs:
        evidence_pages = set(log.get('evidence_pages', []))
        if evidence_pages:
            total += 1
            if evidence_pages.intersection(retrieved_pages):
                correct += 1

    accuracy = (correct / total * 100) if total > 0 else 0.0
    logger.info("\n===== Retrieval Accuracy =====")
    logger.info(f"Accuracy: {accuracy:.2f}% ({correct}/{total})")


def parse_llm_response(response_text: str) -> dict:
    """
    ä»LLMå“åº”ä¸­æå–JSONæ•°æ®ï¼Œå¤„ç†å„ç§å¯èƒ½çš„æ ¼å¼

    Args:
        response_text: æ¨¡å‹è¿”å›çš„åŸå§‹æ–‡æœ¬

    Returns:
        dict: è§£æåçš„JSONå¯¹è±¡
    """
    import re
    import json

    # 1. æ¸…ç†å¯èƒ½çš„markdownä»£ç å—æ ¼å¼
    cleaned_text = re.sub(r'```(?:json|python)?', '', response_text)
    cleaned_text = re.sub(r'`', '', cleaned_text).strip()

    # 2. å°è¯•ç›´æ¥è§£æJSON
    try:
        return json.loads(cleaned_text)
    except json.JSONDecodeError:
        # 3. å°è¯•æŸ¥æ‰¾JSONå†…å®¹
        json_pattern = r'\{[\s\S]*\}'
        match = re.search(json_pattern, cleaned_text)
        if match:
            try:
                return json.loads(match.group(0))
            except json.JSONDecodeError:
                pass

    # 4. å›é€€æ–¹æ¡ˆï¼šæ‰‹åŠ¨æå–å…³é”®å­—æ®µ
    output_dict = {}

    # æå–refined_intent_queriesæ•°ç»„
    queries_pattern = r'"refined_intent_queries"\s*:\s*\[(.*?)\]'
    queries_match = re.search(queries_pattern, cleaned_text, re.DOTALL)
    if queries_match:
        query_items = re.findall(r'"([^"]+)"', queries_match.group(1))
        output_dict["refined_intent_queries"] = query_items

    # æå–intent_queriesæ•°ç»„ï¼ˆå¦‚æœæœ‰ï¼‰
    intent_pattern = r'"intent_queries"\s*:\s*\[(.*?)\]'
    intent_match = re.search(intent_pattern, cleaned_text, re.DOTALL)
    if intent_match:
        intent_items = re.findall(r'"([^"]+)"', intent_match.group(1))
        output_dict["intent_queries"] = intent_items

    return output_dict


# if __name__ == "__main__":
#     # Initialize DeepSearch_Beta instance with parameters
#     retriever = DeepSearch_Beta(params={
#         "embedding_topk": 15,
#         "rerank_topk": 10
#     },
#         reranker=FlagReranker(model_name_or_path="BAAI/bge-reranker-large")
#     )
#
#     # Initialize MultimodalMatcher with external configuration
#     retriever_config = RetrieverConfig(
#         model_name="vidore/colqwen2.5-v0.2",
#         processor_name="vidore/colqwen2.5-v0.1",
#         bge_model_name="BAAI/bge-large-en-v1.5",
#         device="cuda",
#         use_fp16=True,
#         batch_size=32,
#         threshold=0.4,
#         mode="mixed"
#     )
#     matcher = MultimodalMatcher(config=retriever_config)
#
#     # Load test data
#     base_dir = "/Users/chloe/Documents/Academic/AI/Project/åŸºäºColpaliçš„å¤šæ¨¡æ€æ£€ç´¢æ ‡å‡†æ¡†æ¶/multimodal-RAG/DeepRAG_Multimodal/picked_LongDoc"
#     test_data_path = "/Users/chloe/Documents/Academic/AI/Project/åŸºäºColpaliçš„å¤šæ¨¡æ€æ£€ç´¢æ ‡å‡†æ¡†æ¶/multimodal-RAG/DeepRAG_Multimodal/picked_LongDoc/selected_LongDocURL_public_with_subtask_category.jsonl"
#     with open(test_data_path, 'r', encoding='utf-8') as f:
#         for i, line in enumerate(f):
#             doc_data = json.loads(line)
#             documents = []
#             query = doc_data.get("question", "Provide a query here for testing.")  # Extract query from each record
#
#             if "pdf_path" in doc_data:
#                 # Handle PDF documents by converting them into pages
#                 pdf_pages = matcher._pdf_to_pages(os.path.join(base_dir, doc_data["pdf_path"]))
#                 for page_index, page_content in enumerate(pdf_pages):
#                     documents.append({
#                         "text": page_content.get("text", ""),
#                         "image": page_content.get("image", None),
#                         "metadata": {
#                             **doc_data.get("metadata", {}),
#                             "page_index": page_index + 1  # Ensure page_index is added
#                         }
#                     })
#             else:
#                 # Handle regular documents
#                 documents.append(Document(page_content=doc_data['content'], metadata=doc_data.get('metadata', {})))
#
#             data = {
#                 "query": query,  # Use the extracted query
#                 "documents": documents
#             }
#
#             # Perform search retrieval
#             results = retriever.search_retrieval(data, retriever=matcher)
#
#             # Save results to a file for each doc_data
#             results_output_path = f"retrieval_results_{i}.json"
#             with open(results_output_path, 'w', encoding='utf-8') as f_out:
#                 json.dump(results, f_out, ensure_ascii=False, indent=4)
#             logger.info(f"Results saved to {results_output_path}")
#
#             # Extract retrieved pages from results
#             retrieved_pages = set(result['metadata'].get('page_index') for result in results if 'metadata' in result)
#
#             # Calculate and print accuracy
#             calculate_accuracy(test_data_path, retrieved_pages)