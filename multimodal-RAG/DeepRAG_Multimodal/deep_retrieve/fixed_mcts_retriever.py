"""
ä¿®å¤åçš„MCTSæ£€ç´¢å™¨ - è§£å†³æ¥å£ä¸åŒ¹é…å’Œæ•°æ®ç»“æ„é—®é¢˜
"""
from __future__ import annotations
from dataclasses import dataclass, field
from typing import List, Tuple, Dict, Set, Optional, Any
import math
import random
import numpy as np
from copy import deepcopy


# ---------- é€‚é…å™¨ç±» -------------------------------------------------
@dataclass
class Document:
    """æ ‡å‡†åŒ–çš„æ–‡æ¡£æ ¼å¼"""
    doc_id: str
    page_content: str
    score: float = 0.0
    embedding: Optional[np.ndarray] = None
    metadata: Dict = field(default_factory=dict)

    @classmethod
    def from_dict(cls, doc_dict: dict, doc_id: str = None) -> "Document":
        """ä»å­—å…¸åˆ›å»ºDocumentå¯¹è±¡"""
        return cls(
            doc_id=doc_id or str(hash(doc_dict.get("text", ""))),
            page_content=doc_dict.get("text", ""),
            score=doc_dict.get("score", 0.0),
            embedding=doc_dict.get("embedding", None),
            metadata=doc_dict.get("metadata", {})
        )


class MultimodalMatcherAdapter:
    """MultimodalMatcherçš„é€‚é…å™¨ï¼Œæä¾›MCTSéœ€è¦çš„æ¥å£"""

    def __init__(self, base_matcher, documents: List[dict]):
        self.base_matcher = base_matcher
        self.documents = documents  # ç¼“å­˜æ‰€æœ‰æ–‡æ¡£

    def retrieve(self, query: str, top_k: int = 5) -> List[Document]:
        """
        MCTSæœŸæœ›çš„æ¥å£ï¼šåªä¼ å…¥queryå’Œtop_k
        """
        try:
            # è°ƒç”¨åŸå§‹çš„MultimodalMatcher.retrieveæ–¹æ³•
            results = self.base_matcher.retrieve(query, self.documents)

            # è½¬æ¢ä¸ºDocumentæ ¼å¼å¹¶é™åˆ¶æ•°é‡
            documents = []
            for i, result in enumerate(results[:top_k]):
                doc = Document.from_dict(result, doc_id=f"doc_{i}")
                documents.append(doc)

            return documents
        except Exception as e:
            print(f"æ£€ç´¢å‡ºé”™: {str(e)}")
            return []


# ---------- æ•°æ®ç»“æ„ -------------------------------------------------
@dataclass
class State:
    """å·²é€‰æ–‡æ¡£é›†åˆ & å·²è¦†ç›–æ„å›¾é›†åˆ"""
    docs: Set  # {doc_id, ...}
    covered: Set  # {intent_idx, ...}

    def clone(self) -> "State":
        return State(set(self.docs), set(self.covered))


@dataclass
class MCTSNode:
    state: State
    parent: Optional["MCTSNode"]
    action: Optional[Tuple[int, int]]  # (intent_idx, cand_idx)
    children: List["MCTSNode"] = field(default_factory=list)
    visit_count: int = 0
    total_value: float = 0.0
    untried_actions: List[Tuple[int, int]] = field(default_factory=list)

    @property
    def q(self) -> float:
        return self.total_value / self.visit_count if self.visit_count else 0.0


# ---------- ä¿®å¤åçš„MCTSåŒ…è£…å™¨ ----------------------------------------------
class MCTSWrapper:
    """
    ä¿®å¤åçš„MCTSåŒ…è£…å™¨ï¼Œè§£å†³æ¥å£ä¸åŒ¹é…é—®é¢˜
    """

    def __init__(
            self,
            base_retriever,
            rollout_budget: int = 100,  # é™ä½é»˜è®¤å€¼
            k_per_intent: int = 3,  # é™ä½é»˜è®¤å€¼
            max_depth: int = 5,  # é™ä½é»˜è®¤å€¼
            c_puct: float = 1.0,
            reward_weights: Dict[str, float] = None,
            diversity_metric: str = "cos",
            random_seed: int = None,
    ):
        self.base = base_retriever
        self.rollout_budget = rollout_budget
        self.k = k_per_intent
        self.max_depth = max_depth
        self.c_puct = c_puct
        self.rw = reward_weights or {"coverage": 1.0, "quality": 0.5, "diversity": 0.3}
        self.diversity_metric = diversity_metric
        if random_seed is not None:
            random.seed(random_seed)
            np.random.seed(random_seed)

        # è¿è¡Œæ—¶å˜é‡
        self.intent_pool: List[List] = []
        self.doc_embeddings: Dict = {}
        self.adapter = None  # é€‚é…å™¨å°†åœ¨retrieveæ—¶åˆ›å»º

    def retrieve(self, query: str, documents: List[dict]) -> List[dict]:
        """
        ğŸ”¥ æ–°çš„ä¸»è¦æ¥å£ï¼šæ¥æ”¶queryå’Œdocumentsï¼Œè¿”å›æ£€ç´¢ç»“æœ
        è¿™ä¸ªæ–¹æ³•æ›¿ä»£äº†åŸæ¥çš„searchæ–¹æ³•ï¼Œæä¾›æ›´ç¬¦åˆç°æœ‰ä»£ç çš„æ¥å£
        """
        print(f"ğŸ¯ MCTSæ£€ç´¢å¼€å§‹ï¼Œæ–‡æ¡£æ•°é‡: {len(documents)}")

        # åˆ›å»ºé€‚é…å™¨
        self.adapter = MultimodalMatcherAdapter(self.base, documents)

        # 1. é¦–å…ˆè¿›è¡Œæ„å›¾æ‹†è§£ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼Œä½ å¯ä»¥é›†æˆDeepSearch_Betaçš„æ‹†è§£é€»è¾‘ï¼‰
        intents = self._split_query_intents(query)
        print(f"ğŸ” æ‹†è§£æ„å›¾: {intents}")

        # 2. ä½¿ç”¨MCTSè¿›è¡Œæ£€ç´¢
        final_docs = self._mcts_search(query, intents)

        # 3. è½¬æ¢å›åŸå§‹æ ¼å¼
        results = []
        for doc in final_docs:
            results.append({
                "text": doc.page_content,
                "score": doc.score,
                "metadata": doc.metadata
            })

        return results

    def _split_query_intents(self, query: str) -> List[str]:
        """
        ç®€åŒ–çš„æ„å›¾æ‹†è§£ï¼ˆä½ å¯ä»¥æ›¿æ¢ä¸ºDeepSearch_Betaçš„æ‹†è§£é€»è¾‘ï¼‰
        """
        # è¿™é‡Œæ˜¯ä¸€ä¸ªç®€åŒ–çš„å®ç°ï¼Œä½ å¯ä»¥æ›¿æ¢ä¸ºä½ çš„å¤šæ„å›¾æ‹†è§£é€»è¾‘
        intents = [
            query,  # åŸå§‹æŸ¥è¯¢
            f"è¯¦ç»†è§£é‡Š {query}",  # ç†è§£æ„å›¾
            f"åˆ†æ {query} çš„å…³é”®ä¿¡æ¯",  # æ¨ç†æ„å›¾
            f"æ‰¾åˆ°å…³äº {query} çš„å…·ä½“å†…å®¹"  # å®šä½æ„å›¾
        ]
        return intents

    def _mcts_search(self, original_query: str, intents: List[str]) -> List[Document]:
        """
        MCTSæœç´¢ä¸»é€»è¾‘
        """
        try:
            self._prefetch(intents)

            root = MCTSNode(state=State(set(), set()), parent=None, action=None)
            root.untried_actions = [(i, j) for i in range(len(intents))
                                    for j in range(len(self.intent_pool[i]))]

            # ğŸ”¥ æ·»åŠ æ£€æŸ¥é¿å…æ— é™å¾ªç¯
            if not root.untried_actions:
                print("âš ï¸ æ²¡æœ‰å¯ç”¨çš„åŠ¨ä½œï¼Œè¿”å›ç©ºç»“æœ")
                return []

            for iteration in range(min(self.rollout_budget, 50)):  # é™åˆ¶æœ€å¤§è¿­ä»£æ¬¡æ•°
                try:
                    path = self._select(root)
                    leaf = self._expand(path[-1])
                    reward = self._simulate(leaf)
                    self._backprop(path, reward)
                except Exception as e:
                    print(f"âš ï¸ MCTSè¿­ä»£ {iteration} å‡ºé”™: {str(e)}")
                    continue

            # æ‰¾è®¿é—®æ¬¡æ•°æœ€å¤šçš„å­èŠ‚ç‚¹ä½œä¸ºbest
            if not root.children:
                print("âš ï¸ æ²¡æœ‰å­èŠ‚ç‚¹ï¼Œè¿”å›å‰kä¸ªæ–‡æ¡£")
                # å›é€€ç­–ç•¥ï¼šè¿”å›ç¬¬ä¸€ä¸ªæ„å›¾çš„å‰å‡ ä¸ªæ–‡æ¡£
                if self.intent_pool:
                    return self.intent_pool[0][:self.max_depth]
                return []

            best_child = max(root.children, key=lambda n: n.visit_count)
            final_doc_ids = best_child.state.docs

            # è½¬æ¢doc_idå›Documentå¯¹è±¡
            final_docs = []
            for doc_id in final_doc_ids:
                doc = self._doc_by_id(doc_id)
                if doc:
                    final_docs.append(doc)

            return final_docs

        except Exception as e:
            print(f"âŒ MCTSæœç´¢å‡ºé”™: {str(e)}")
            # å›é€€ç­–ç•¥ï¼šä½¿ç”¨åŸºç¡€æ£€ç´¢å™¨
            if self.adapter:
                return self.adapter.retrieve(original_query, self.max_depth)
            return []

    def _prefetch(self, intents: List[str]):
        """é¢„å–æ¯ä¸ªæ„å›¾çš„æ–‡æ¡£"""
        self.intent_pool.clear()
        self.doc_embeddings.clear()

        for intent in intents:
            try:
                # ğŸ”¥ ä½¿ç”¨é€‚é…å™¨è°ƒç”¨
                docs = self.adapter.retrieve(intent, top_k=self.k)
                self.intent_pool.append(docs)

                # ç¼“å­˜embeddings
                for doc in docs:
                    if doc.embedding is not None:
                        self.doc_embeddings[doc.doc_id] = np.asarray(doc.embedding)

            except Exception as e:
                print(f"âš ï¸ é¢„å–æ„å›¾ '{intent}' å¤±è´¥: {str(e)}")
                self.intent_pool.append([])  # æ·»åŠ ç©ºåˆ—è¡¨é¿å…ç´¢å¼•é”™è¯¯

    def _select(self, node: MCTSNode) -> List[MCTSNode]:
        """æ²¿ç€UCTæœ€å¤§çš„childä¸‹è¡Œï¼Œç›´åˆ°å¶èŠ‚ç‚¹"""
        path = [node]
        max_iterations = 20  # é˜²æ­¢æ— é™å¾ªç¯
        iteration = 0

        while node.children and not node.untried_actions and iteration < max_iterations:
            if not node.children:
                break

            log_N = math.log(max(node.visit_count, 1))  # é¿å…log(0)

            def uct(n: MCTSNode) -> float:
                if n.visit_count == 0:
                    return float('inf')  # ä¼˜å…ˆè®¿é—®æœªè®¿é—®çš„èŠ‚ç‚¹
                return n.q + self.c_puct * math.sqrt(log_N / n.visit_count)

            node = max(node.children, key=uct)
            path.append(node)
            iteration += 1

        return path

    def _expand(self, node: MCTSNode) -> MCTSNode:
        """æ‰©å±•èŠ‚ç‚¹"""
        if not node.untried_actions or len(node.state.docs) >= self.max_depth:
            return node

        action = node.untried_actions.pop(random.randrange(len(node.untried_actions)))
        intent_idx, cand_idx = action

        # æ£€æŸ¥ç´¢å¼•æœ‰æ•ˆæ€§
        if (intent_idx >= len(self.intent_pool) or
                cand_idx >= len(self.intent_pool[intent_idx])):
            return node

        doc = self.intent_pool[intent_idx][cand_idx]

        new_state = node.state.clone()
        new_state.docs.add(doc.doc_id)
        new_state.covered.add(intent_idx)

        child = MCTSNode(state=new_state, parent=node, action=action)
        child.untried_actions = [a for a in node.untried_actions
                                 if a[0] != intent_idx or self.intent_pool[a[0]][a[1]].doc_id not in new_state.docs]
        node.children.append(child)
        return child

    def _simulate(self, node: MCTSNode) -> float:
        """æ¨¡æ‹Ÿrollout"""
        state = node.state.clone()
        remaining_actions = node.untried_actions.copy()
        random.shuffle(remaining_actions)

        simulation_steps = 0
        max_simulation_steps = min(10, self.max_depth)  # é™åˆ¶æ¨¡æ‹Ÿæ­¥æ•°

        while (remaining_actions and
               len(state.docs) < self.max_depth and
               len(state.covered) < len(self.intent_pool) and
               simulation_steps < max_simulation_steps):

            action = remaining_actions.pop()
            intent_idx, cand_idx = action

            # æ£€æŸ¥ç´¢å¼•æœ‰æ•ˆæ€§
            if (intent_idx >= len(self.intent_pool) or
                    cand_idx >= len(self.intent_pool[intent_idx])):
                continue

            doc = self.intent_pool[intent_idx][cand_idx]
            if doc.doc_id in state.docs:
                continue

            state.docs.add(doc.doc_id)
            state.covered.add(intent_idx)
            simulation_steps += 1

        return self._reward(state)

    def _backprop(self, path: List[MCTSNode], reward: float):
        """åå‘ä¼ æ’­å¥–åŠ±"""
        for node in path:
            node.visit_count += 1
            node.total_value += reward

    def _reward(self, state: State) -> float:
        """è®¡ç®—å¥–åŠ±"""
        try:
            # 1. æ„å›¾è¦†ç›–å¥–åŠ±
            coverage_r = len(state.covered) / max(len(self.intent_pool), 1)

            # 2. æ–‡æ¡£è´¨é‡å¥–åŠ±
            if state.docs:
                scores = []
                for doc_id in state.docs:
                    doc = self._doc_by_id(doc_id)
                    if doc:
                        scores.append(doc.score)
                quality_r = np.mean(scores) if scores else 0.0
            else:
                quality_r = 0.0

            # 3. å¤šæ ·æ€§å¥–åŠ±
            diversity_r = 0.0
            if len(state.docs) > 1 and self.rw.get("diversity", 0) > 0:
                valid_embeddings = []
                for doc_id in state.docs:
                    if doc_id in self.doc_embeddings:
                        valid_embeddings.append(self.doc_embeddings[doc_id])

                if len(valid_embeddings) >= 2:
                    embs = np.stack(valid_embeddings)
                    norm = np.linalg.norm(embs, axis=1, keepdims=True) + 1e-10
                    embs_norm = embs / norm
                    sim = embs_norm @ embs_norm.T
                    upper = sim[np.triu_indices(len(embs), k=1)]
                    diversity_r = 1.0 - np.mean(upper) if len(upper) > 0 else 0.0

            total_reward = (self.rw["coverage"] * coverage_r +
                            self.rw["quality"] * quality_r +
                            self.rw["diversity"] * diversity_r)

            return max(0.0, min(1.0, total_reward))  # é™åˆ¶åœ¨[0,1]èŒƒå›´å†…

        except Exception as e:
            print(f"âš ï¸ å¥–åŠ±è®¡ç®—å‡ºé”™: {str(e)}")
            return 0.0

    def _doc_by_id(self, doc_id):
        """æ ¹æ®doc_idæŸ¥æ‰¾æ–‡æ¡£"""
        for bucket in self.intent_pool:
            for doc in bucket:
                if doc.doc_id == doc_id:
                    return doc
        return None