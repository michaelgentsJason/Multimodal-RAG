#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
è¯„åˆ†è¯Šæ–­æµ‹è¯•è„šæœ¬ - å¿«é€Ÿè¯Šæ–­ä¸ºä»€ä¹ˆæ£€ç´¢åˆ†æ•°å…¨æ˜¯0

ç”¨æ³•:
python score_diagnostic_test.py
"""

import os
import sys
import json
import time
import torch
import numpy as np
from dotenv import load_dotenv
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger(__name__)

# æ·»åŠ å¿…è¦çš„è·¯å¾„
sys.path.append("multimodal-RAG/DeepRAG_Multimodal/deep_retrieve")
load_dotenv("multimodal-RAG/DeepRAG_Multimodal/configs/.env")

# è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆå¦‚æœéœ€è¦ï¼‰
if os.getenv("SILICONFLOW_API_KEY"):
    logger.info("âœ… æ‰¾åˆ°ç¡…åŸºæµåŠ¨API Key")
else:
    logger.warning("âš ï¸ æœªæ‰¾åˆ°ç¡…åŸºæµåŠ¨API Key")


class ScoreDiagnosticTester:
    """è¯„åˆ†è¯Šæ–­æµ‹è¯•å™¨"""

    def __init__(self):
        """åˆå§‹åŒ–æµ‹è¯•å™¨"""
        self.device = "cuda:0" if torch.cuda.is_available() else "cpu"
        logger.info(f"ğŸ® ä½¿ç”¨è®¾å¤‡: {self.device}")

        # æµ‹è¯•ç”¨ä¾‹
        self.test_query = "What are the key features of Huddle section?"
        self.test_documents = [
            {
                "text": "Huddle section key features include real-time collaboration, document sharing, video conferencing, project management tools, team communication capabilities, screen sharing, whiteboard tools, calendar integration, and notification systems.",
                "metadata": {"page_index": 1, "pdf_path": "test.pdf"}
            },
            {
                "text": "The Huddle platform offers advanced collaboration features such as customizable workspace layouts, cloud storage integration, API connectivity, mobile accessibility, security encryption, and user permission controls.",
                "metadata": {"page_index": 2, "pdf_path": "test.pdf"}
            },
            {
                "text": "Huddle section encompasses cross-platform compatibility, automated workflow processes, real-time document editing, version control, team performance analytics, meeting scheduling, and comprehensive reporting tools.",
                "metadata": {"page_index": 3, "pdf_path": "test.pdf"}
            }
        ]

        logger.info(f"ğŸ§ª æµ‹è¯•æŸ¥è¯¢: {self.test_query}")
        logger.info(f"ğŸ“š æµ‹è¯•æ–‡æ¡£æ•°é‡: {len(self.test_documents)}")

    def test_1_cuda_availability(self):
        """æµ‹è¯•1: CUDAå¯ç”¨æ€§"""
        logger.info("\n" + "=" * 60)
        logger.info("ğŸ§ª æµ‹è¯•1: CUDAå¯ç”¨æ€§æ£€æŸ¥")
        logger.info("=" * 60)

        try:
            logger.info(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")
            if torch.cuda.is_available():
                logger.info(f"GPUæ•°é‡: {torch.cuda.device_count()}")
                logger.info(f"å½“å‰GPU: {torch.cuda.current_device()}")
                logger.info(f"GPUåç§°: {torch.cuda.get_device_name()}")
                logger.info(f"GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024 ** 3:.1f}GB")

                # æµ‹è¯•GPUè®¡ç®—
                test_tensor = torch.randn(100, 100).to(self.device)
                result = torch.mm(test_tensor, test_tensor.T)
                logger.info(f"âœ… GPUè®¡ç®—æµ‹è¯•æˆåŠŸ: {result.shape}")
                return True
            else:
                logger.warning("âš ï¸ CUDAä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPU")
                return False
        except Exception as e:
            logger.error(f"âŒ CUDAæµ‹è¯•å¤±è´¥: {e}")
            return False

    def test_2_bge_model_direct(self):
        """æµ‹è¯•2: BGEæ¨¡å‹ç›´æ¥æµ‹è¯•"""
        logger.info("\n" + "=" * 60)
        logger.info("ğŸ§ª æµ‹è¯•2: BGEæ¨¡å‹ç›´æ¥æµ‹è¯•")
        logger.info("=" * 60)

        try:
            from FlagEmbedding import FlagModel

            logger.info("â³ åŠ è½½BGEæ¨¡å‹...")
            start_time = time.time()

            bge_model = FlagModel(
                "BAAI/bge-large-en-v1.5",
                query_instruction_for_retrieval="Represent this sentence for searching relevant passages:",
                use_fp16=True,
                device=self.device
            )

            load_time = time.time() - start_time
            logger.info(f"âœ… BGEæ¨¡å‹åŠ è½½å®Œæˆï¼Œè€—æ—¶: {load_time:.2f}ç§’")

            # æµ‹è¯•åµŒå…¥è®¡ç®—
            query_emb = bge_model.encode([self.test_query])
            text_emb = bge_model.encode([self.test_documents[0]["text"]])

            # è®¡ç®—ç›¸ä¼¼åº¦
            similarity = float(query_emb @ text_emb.T)

            logger.info(f"ğŸ“Š æŸ¥è¯¢åµŒå…¥å½¢çŠ¶: {query_emb.shape}")
            logger.info(f"ğŸ“Š æ–‡æœ¬åµŒå…¥å½¢çŠ¶: {text_emb.shape}")
            logger.info(f"ğŸ¯ ç›¸ä¼¼åº¦åˆ†æ•°: {similarity:.6f}")

            if similarity > 0:
                logger.info("âœ… BGEæ¨¡å‹å·¥ä½œæ­£å¸¸")
                return True, bge_model
            else:
                logger.error("âŒ BGEæ¨¡å‹è¿”å›0åˆ†æ•°")
                return False, None

        except Exception as e:
            logger.error(f"âŒ BGEæ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False, None

    def test_3_reranker_direct(self):
        """æµ‹è¯•3: FlagRerankerç›´æ¥æµ‹è¯•"""
        logger.info("\n" + "=" * 60)
        logger.info("ğŸ§ª æµ‹è¯•3: FlagRerankerç›´æ¥æµ‹è¯•")
        logger.info("=" * 60)

        try:
            from FlagEmbedding import FlagReranker

            logger.info("â³ åŠ è½½FlagReranker...")
            start_time = time.time()

            reranker = FlagReranker(
                model_name_or_path="BAAI/bge-reranker-large",
                use_fp16=True,
                device=self.device
            )

            load_time = time.time() - start_time
            logger.info(f"âœ… FlagRerankeråŠ è½½å®Œæˆï¼Œè€—æ—¶: {load_time:.2f}ç§’")

            # æµ‹è¯•é‡æ’åº
            pairs = [[self.test_query, doc["text"]] for doc in self.test_documents]
            rerank_scores = reranker.compute_score(pairs, normalize=True)

            logger.info(f"ğŸ“Š é‡æ’åºå¯¹æ•°: {len(pairs)}")
            logger.info(f"ğŸ¯ é‡æ’åºåˆ†æ•°: {rerank_scores}")

            # æ£€æŸ¥åˆ†æ•°
            max_score = max(rerank_scores) if rerank_scores else 0
            if max_score > 0:
                logger.info("âœ… FlagRerankerå·¥ä½œæ­£å¸¸")
                return True, reranker
            else:
                logger.error("âŒ FlagRerankerè¿”å›å…¨0åˆ†æ•°")
                return False, None

        except Exception as e:
            logger.error(f"âŒ FlagRerankeræµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False, None

    def test_4_multimodal_matcher(self):
        """æµ‹è¯•4: MultimodalMatcheræµ‹è¯•"""
        logger.info("\n" + "=" * 60)
        logger.info("ğŸ§ª æµ‹è¯•4: MultimodalMatcheræµ‹è¯•")
        logger.info("=" * 60)

        try:
            from DeepRAG_Multimodal.deep_retrieve.retriever_multimodal_bge import RetrieverConfig, MultimodalMatcher

            logger.info("â³ åˆå§‹åŒ–MultimodalMatcher...")

            # é…ç½®
            retriever_config = RetrieverConfig(
                model_name="vidore/colqwen2.5-v0.2",
                processor_name="vidore/colqwen2.5-v0.1",
                bge_model_name="BAAI/bge-large-en-v1.5",
                device=self.device,
                use_fp16=True,
                batch_size=2,
                mode='text_only',  # åªç”¨æ–‡æœ¬æ¨¡å¼åŠ å¿«æµ‹è¯•
                ocr_method='paddleocr'
            )

            matcher = MultimodalMatcher(
                config=retriever_config,
                embedding_weight=1.0,  # çº¯æ–‡æœ¬
                topk=5
            )

            logger.info("âœ… MultimodalMatcheråˆå§‹åŒ–å®Œæˆ")

            # æ‰§è¡Œæ£€ç´¢
            logger.info("â³ æ‰§è¡Œæ£€ç´¢...")
            results = matcher.retrieve(self.test_query, self.test_documents)

            logger.info(f"ğŸ“Š æ£€ç´¢ç»“æœæ•°é‡: {len(results)}")

            # åˆ†æç»“æœ
            for i, result in enumerate(results):
                score = result.get('score', 0)
                text_preview = result.get('text', '')[:60] + "..."
                logger.info(f"   ç»“æœ{i + 1}: åˆ†æ•°={score:.6f}, æ–‡æœ¬='{text_preview}'")

            # æ£€æŸ¥åˆ†æ•°
            scores = [r.get('score', 0) for r in results]
            max_score = max(scores) if scores else 0

            if max_score > 0:
                logger.info("âœ… MultimodalMatcherå·¥ä½œæ­£å¸¸")
                return True, matcher, results
            else:
                logger.error("âŒ MultimodalMatcherè¿”å›å…¨0åˆ†æ•°")

                # è¯¦ç»†è°ƒè¯•
                logger.info("ğŸ” å¼€å§‹è¯¦ç»†è°ƒè¯•...")
                for i, doc in enumerate(self.test_documents):
                    text = doc.get('text', '')
                    logger.info(f"ğŸ“„ æ–‡æ¡£{i + 1} é•¿åº¦: {len(text)} å­—ç¬¦")

                    # æ‰‹åŠ¨æµ‹è¯•æ–‡æœ¬åˆ†æ•°è®¡ç®—
                    try:
                        if hasattr(matcher, '_compute_text_score'):
                            manual_score = matcher._compute_text_score(self.test_query, text)
                            logger.info(f"ğŸ“„ æ–‡æ¡£{i + 1} æ‰‹åŠ¨è®¡ç®—åˆ†æ•°: {manual_score:.6f}")
                    except Exception as e:
                        logger.error(f"ğŸ“„ æ–‡æ¡£{i + 1} æ‰‹åŠ¨è®¡ç®—å¤±è´¥: {e}")

                return False, None, []

        except Exception as e:
            logger.error(f"âŒ MultimodalMatcheræµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False, None, []

    def test_5_full_pipeline(self):
        """æµ‹è¯•5: å®Œæ•´æ£€ç´¢æµæ°´çº¿"""
        logger.info("\n" + "=" * 60)
        logger.info("ğŸ§ª æµ‹è¯•5: å®Œæ•´æ£€ç´¢æµæ°´çº¿æµ‹è¯•")
        logger.info("=" * 60)

        try:
            # å¯¼å…¥æ‰€éœ€æ¨¡å—
            from DeepRAG_Multimodal.deep_retrieve.ming.deepsearch_optimize_ming import DeepSearch_Beta
            from DeepRAG_Multimodal.deep_retrieve.retriever_multimodal_bge import RetrieverConfig, MultimodalMatcher
            from FlagEmbedding import FlagReranker

            logger.info("â³ åˆå§‹åŒ–å®Œæ•´æµæ°´çº¿...")

            # åˆå§‹åŒ–ç»„ä»¶
            reranker = FlagReranker(
                model_name_or_path="BAAI/bge-reranker-large",
                use_fp16=True,
                device=self.device
            )

            retriever_config = RetrieverConfig(
                model_name="vidore/colqwen2.5-v0.2",
                processor_name="vidore/colqwen2.5-v0.1",
                bge_model_name="BAAI/bge-large-en-v1.5",
                device=self.device,
                use_fp16=True,
                batch_size=2,
                mode='text_only',
                ocr_method='paddleocr'
            )

            matcher = MultimodalMatcher(
                config=retriever_config,
                embedding_weight=1.0,
                topk=5
            )

            # åˆ›å»ºç®€åŒ–çš„æ£€ç´¢å™¨ï¼ˆä¸ä½¿ç”¨æ„å›¾æ‹†è§£ï¼‰
            class SimpleRetriever:
                def __init__(self, matcher, reranker):
                    self.matcher = matcher
                    self.reranker = reranker

                def search_retrieval(self, data, retriever=None):
                    query = data['query']
                    documents = data['documents']

                    logger.info(f"ğŸ” æ£€ç´¢æŸ¥è¯¢: {query}")
                    logger.info(f"ğŸ“š æ–‡æ¡£æ•°é‡: {len(documents)}")

                    # ç›´æ¥æ£€ç´¢
                    results = self.matcher.retrieve(query, documents)

                    # è®°å½•åˆå§‹åˆ†æ•°
                    initial_scores = [r.get('score', 0) for r in results]
                    logger.info(f"ğŸ“Š åˆå§‹åˆ†æ•°: {initial_scores}")

                    # é‡æ’åºï¼ˆå¦‚æœæœ‰ç»“æœï¼‰
                    if results and any(s > 0 for s in initial_scores):
                        try:
                            pairs = [[query, r.get('text', '')] for r in results]
                            rerank_scores = self.reranker.compute_score(pairs, normalize=True)

                            # æ›´æ–°åˆ†æ•°
                            for i, result in enumerate(results):
                                if i < len(rerank_scores):
                                    result['rerank_score'] = rerank_scores[i]
                                    # ç»„åˆåˆ†æ•°
                                    original_score = result.get('score', 0)
                                    result['final_score'] = 0.6 * rerank_scores[i] + 0.4 * original_score

                            logger.info(f"ğŸ“Š é‡æ’åºåˆ†æ•°: {rerank_scores}")

                        except Exception as e:
                            logger.warning(f"âš ï¸ é‡æ’åºå¤±è´¥: {e}")

                    return results

            simple_retriever = SimpleRetriever(matcher, reranker)

            # æµ‹è¯•æ•°æ®
            test_data = {
                'query': self.test_query,
                'documents': self.test_documents
            }

            # æ‰§è¡Œå®Œæ•´æ£€ç´¢
            logger.info("â³ æ‰§è¡Œå®Œæ•´æ£€ç´¢æµæ°´çº¿...")
            start_time = time.time()

            final_results = simple_retriever.search_retrieval(test_data)

            elapsed_time = time.time() - start_time
            logger.info(f"âœ… å®Œæ•´æ£€ç´¢å®Œæˆï¼Œè€—æ—¶: {elapsed_time:.2f}ç§’")

            # åˆ†ææœ€ç»ˆç»“æœ
            logger.info(f"ğŸ“Š æœ€ç»ˆç»“æœæ•°é‡: {len(final_results)}")

            for i, result in enumerate(final_results):
                score = result.get('final_score', result.get('score', 0))
                rerank_score = result.get('rerank_score', 'N/A')
                text_preview = result.get('text', '')[:50] + "..."
                logger.info(f"   ç»“æœ{i + 1}: æœ€ç»ˆåˆ†æ•°={score:.6f}, é‡æ’åºåˆ†æ•°={rerank_score}, æ–‡æœ¬='{text_preview}'")

            # æ£€æŸ¥æ˜¯å¦æˆåŠŸ
            final_scores = [r.get('final_score', r.get('score', 0)) for r in final_results]
            max_final_score = max(final_scores) if final_scores else 0

            if max_final_score > 0:
                logger.info("âœ… å®Œæ•´æµæ°´çº¿å·¥ä½œæ­£å¸¸")
                return True
            else:
                logger.error("âŒ å®Œæ•´æµæ°´çº¿è¿”å›å…¨0åˆ†æ•°")
                return False

        except Exception as e:
            logger.error(f"âŒ å®Œæ•´æµæ°´çº¿æµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False

    def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        logger.info("ğŸš€ å¼€å§‹è¯„åˆ†è¯Šæ–­æµ‹è¯•...")
        logger.info(f"ğŸ“Š æµ‹è¯•æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}")

        test_results = {}

        # æµ‹è¯•1: CUDA
        test_results['cuda'] = self.test_1_cuda_availability()

        # æµ‹è¯•2: BGEæ¨¡å‹
        bge_success, bge_model = self.test_2_bge_model_direct()
        test_results['bge_direct'] = bge_success

        # æµ‹è¯•3: FlagReranker
        reranker_success, reranker = self.test_3_reranker_direct()
        test_results['reranker_direct'] = reranker_success

        # æµ‹è¯•4: MultimodalMatcher
        matcher_success, matcher, results = self.test_4_multimodal_matcher()
        test_results['multimodal_matcher'] = matcher_success

        # æµ‹è¯•5: å®Œæ•´æµæ°´çº¿
        pipeline_success = self.test_5_full_pipeline()
        test_results['full_pipeline'] = pipeline_success

        # æ€»ç»“æŠ¥å‘Š
        self.print_summary_report(test_results)

        return test_results

    def print_summary_report(self, test_results):
        """æ‰“å°æ€»ç»“æŠ¥å‘Š"""
        logger.info("\n" + "=" * 60)
        logger.info("ğŸ“‹ è¯Šæ–­æµ‹è¯•æ€»ç»“æŠ¥å‘Š")
        logger.info("=" * 60)

        all_passed = True
        for test_name, result in test_results.items():
            status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
            logger.info(f"{test_name:20s}: {status}")
            if not result:
                all_passed = False

        logger.info("\n" + "=" * 60)
        if all_passed:
            logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼è¯„åˆ†ç³»ç»Ÿåº”è¯¥æ­£å¸¸å·¥ä½œã€‚")
            logger.info("ğŸ’¡ å¦‚æœdemoä¸­ä»ç„¶æ˜¯0åˆ†ï¼Œé—®é¢˜å¯èƒ½åœ¨æ•°æ®å¤„ç†æˆ–é…ç½®ä¸Šã€‚")
        else:
            logger.info("âš ï¸ å‘ç°é—®é¢˜ï¼è¯·æŸ¥çœ‹ä¸Šé¢çš„è¯¦ç»†é”™è¯¯ä¿¡æ¯ã€‚")

            # æä¾›å…·ä½“å»ºè®®
            if not test_results.get('cuda', True):
                logger.info("ğŸ”§ å»ºè®®: æ£€æŸ¥CUDAå®‰è£…å’ŒGPUé©±åŠ¨")
            if not test_results.get('bge_direct', True):
                logger.info("ğŸ”§ å»ºè®®: æ£€æŸ¥BGEæ¨¡å‹ä¸‹è½½å’Œè®¾å¤‡é…ç½®")
            if not test_results.get('reranker_direct', True):
                logger.info("ğŸ”§ å»ºè®®: æ£€æŸ¥FlagRerankeræ¨¡å‹å’Œè®¾å¤‡é…ç½®")
            if not test_results.get('multimodal_matcher', True):
                logger.info("ğŸ”§ å»ºè®®: æ£€æŸ¥MultimodalMatcheré…ç½®å’Œæ–‡æœ¬é¢„å¤„ç†")
            if not test_results.get('full_pipeline', True):
                logger.info("ğŸ”§ å»ºè®®: æ£€æŸ¥å®Œæ•´æµæ°´çº¿çš„ç»„ä»¶é›†æˆ")

        logger.info("=" * 60)


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§ª è¯„åˆ†è¯Šæ–­æµ‹è¯•è„šæœ¬")
    print("=" * 60)
    print("è¿™ä¸ªè„šæœ¬å°†å¿«é€Ÿè¯Šæ–­ä¸ºä»€ä¹ˆæ£€ç´¢åˆ†æ•°å…¨æ˜¯0")
    print("=" * 60)

    try:
        tester = ScoreDiagnosticTester()
        results = tester.run_all_tests()

        # ä¿å­˜ç»“æœ
        result_file = "score_diagnostic_results.json"
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump({
                'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
                'test_results': results,
                'test_query': tester.test_query,
                'device': tester.device
            }, f, indent=2)

        print(f"\nğŸ“ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {result_file}")

    except KeyboardInterrupt:
        print("\nâš ï¸ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
